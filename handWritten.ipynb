{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:02:57.901461598Z",
     "start_time": "2023-05-03T13:02:57.273630638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# digits: 10; # samples: 1797; # features 64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "#design a torch nn that classifies digits images using conv layers\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_digits):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, n_digits)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:02:58.789435572Z",
     "start_time": "2023-05-03T13:02:57.906624747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in tqdm(range(1, 100)):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:02:58.796040672Z",
     "start_time": "2023-05-03T13:02:58.794700604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1797, 1, 8, 8)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.reshape(data, (len(data), 1, 8, 8))\n",
    "data2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:02:58.826159807Z",
     "start_time": "2023-05-03T13:02:58.797026547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long()), batch_size=128, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:02:58.826497322Z",
     "start_time": "2023-05-03T13:02:58.814656818Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:09<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.857611179351807 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model = ConvNet(n_digits).to(device)\n",
    "start_time = time.time()\n",
    "train(model, train_loader)\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:08.689902693Z",
     "start_time": "2023-05-03T13:02:58.819848821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(torch.from_numpy(X_test).float().to(device))\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, pred.argmax(dim=1).cpu().numpy())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:08.757960027Z",
     "start_time": "2023-05-03T13:03:08.690438101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 2 7 5 9 8 4 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = np.random.randint(0, len(X_test), 10)\n",
    "pred_samples = np.argmax(model(torch.from_numpy(X_test[samples]).float().to(device)).detach().cpu().numpy(), axis = 1)\n",
    "real_labels = y_test[samples]\n",
    "print(pred_samples)\n",
    "sample_images = X_test[samples].reshape(10, 8, 8)\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(sample_images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    axes[i].set_xticks(())\n",
    "    axes[i].set_yticks(())\n",
    "    axes[i].set_xlabel(f\"pred: {pred_samples[i]}\\n Real {real_labels[i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:09.154110515Z",
     "start_time": "2023-05-03T13:03:08.719110260Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Good! Let's try with MNIST database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f9486feebd0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:09.154758724Z",
     "start_time": "2023-05-03T13:03:09.137591419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:09.349282467Z",
     "start_time": "2023-05-03T13:03:09.137784605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 64, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:09.393945974Z",
     "start_time": "2023-05-03T13:03:09.353116491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs)):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:03:09.394450492Z",
     "start_time": "2023-05-03T13:03:09.393674325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [02:24<03:03, 36.62s/it]"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "start_time = time.time()\n",
    "train(model, train_loader)\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")\n",
    "#torch.save(model, \"./models/mnist_model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:03:09.394264333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/mnist_model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "samples = np.random.randint(0, len(example_data), 10)\n",
    "pred_samples = np.argmax(model(example_data[samples].to(device)).detach().cpu().numpy(), axis = 1)\n",
    "real_targets = example_targets[samples]\n",
    "\n",
    "sample_images = example_data[samples].reshape(10, 28, 28)\n",
    "fig, axes = plt.subplots(1, 10, figsize=(20, 10))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(sample_images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    axes[i].set_xticks(())\n",
    "    axes[i].set_yticks(())\n",
    "    axes[i].set_xlabel(f\"pred: {pred_samples[i]}\\n Real {real_targets[i]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = None\n",
    "labels = None\n",
    "for img, lab in train_loader:\n",
    "    if images is None:\n",
    "        images = np.array(img)\n",
    "        labels = np.array(lab)\n",
    "    else:\n",
    "        images = np.concatenate((images, img), axis = 0)\n",
    "        labels = np.concatenate((labels, lab), axis = 0)\n",
    "\n",
    "for img, lab in test_loader:\n",
    "    if images is None:\n",
    "        images = np.array(img)\n",
    "        labels = np.array(lab)\n",
    "    else:\n",
    "        images = np.concatenate((images, img), axis = 0)\n",
    "        labels = np.concatenate((labels, lab), axis = 0)\n",
    "\n",
    "images = images.reshape(len(images), 28, 28)\n",
    "images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def median_matrix(matrices):\n",
    "    # Step 1: Flatten each matrix into a vector\n",
    "    flattened_matrices = [matrix.flatten() for matrix in matrices]\n",
    "\n",
    "    # Step 2: Stack the flattened matrices\n",
    "    stacked_matrix = np.column_stack(flattened_matrices)\n",
    "\n",
    "    # Step 3: Compute the median vector\n",
    "    median_vector = np.median(stacked_matrix, axis=1)\n",
    "\n",
    "    # Step 4: Reshape the median vector\n",
    "    return median_vector.reshape(matrices[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "med = None\n",
    "for i in range(10):\n",
    "    if med is None:\n",
    "        med = np.array([median_matrix(images[np.where(labels == i)])])\n",
    "    else:\n",
    "        med = np.append(med, [median_matrix(images[np.where(labels == i)])], axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def thresholding(img, threshold):\n",
    "    img[img < threshold] = 0\n",
    "    img[img >= threshold] = 120\n",
    "    return img\n",
    "\n",
    "#med = np.array([thresholding(med[i], 0.8) for i in range(10)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(med[9], cmap = \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The classes are balanced so i will take a 10 percent of sampled as unclassifiable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{i}: {len(labels[labels == i]) / len(labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def get_cosine_similarity(image, median_image):\n",
    "     return np.dot(image.flatten(),median_image.flatten())/(norm(image.flatten())*norm(median_image.flatten()))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_images = thresholding(images, 0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(t_images[3], cmap = \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances = []\n",
    "new_labels = labels.copy()\n",
    "for i in range(10):\n",
    "    i_digits = images[np.where(labels == i)]\n",
    "    #distances.append([np.mean((med[i] - img)**2) for img in i_digits])\n",
    "    #index_largest = np.argsort(distances[i])[-50:] #i take the worst 5 percent\n",
    "    distances.append([get_cosine_similarity(img, med[i]) for img in i_digits])\n",
    "    #index_largest = np.argsort(distances[i])[:int(len(distances[i]) * 0.05)] #i take the worst 5 percent\n",
    "    #index_largest = np.where(distances > 0.7)\n",
    "    index_largest = np.where(np.array(distances[i]) < 0.1)[0]\n",
    "    new_labels[index_largest] = 10 #I mark with 10 the worst images"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(np.where(new_labels == 10)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels[sample]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample = np.where(new_labels == 10)[0][np.random.randint(0, 73, 1)[0]]\n",
    "print(labels[sample])\n",
    "plt.imshow(images[sample], cmap = \"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cosine_labels = []\n",
    "for i, img in enumerate(images):\n",
    "    dist = [get_cosine_similarity(img, med[j]) for j in range(10)]\n",
    "    cosine_labels.append(np.argmax(dist))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#compare how many cosine_labes are equals to the labels\n",
    "print(f\"Accuracy: {np.sum(np.array(cosine_labels) == labels) / len(labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
